{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree-based Modelling EDA\n",
    "Using the existing DataLoader and DataCleaner functionality, I aim to explore different tree-based models. I am expecting to settle for a XGBoost model.\n",
    "\n",
    "I will also use this notebook to explore feature selection techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pyZak/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "from data_preprocessing.DataLoader import DataLoader\n",
    "from data_preprocessing.DataCleaner import DataCleaner\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modelling\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesClassifier\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# Hyper param Tuning\n",
    "from hpsklearn import HyperoptEstimator, random_forest_regressor, xgboost_regression\n",
    "from hyperopt import hp\n",
    "\n",
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('X_train.csv')\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_train = pd.read_csv('y_train.csv')\n",
    "y_test = pd.read_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_loader = DataLoader(path=\"car_data.parquet.gzip\")\n",
    "# df = data_loader.load_parquet()\n",
    "# data_cleaner = DataCleaner(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaner.clean_data()\n",
    "# new_df = data_cleaner.get_df()\n",
    "# # Split data and drop old columns\n",
    "# X_train, X_test, y_train, y_test = data_loader.split_data(new_df)\n",
    "# data_cleaner.drop_columns(X_train)\n",
    "# data_cleaner.drop_columns(X_test)\n",
    "# # Encode to ordinal bsaed on train set\n",
    "# columns_to_ordinal = [\"co2_grouped\", \"engine_size_grouped\", \"owners_grouped\", \"fuel_type_grouped\", \"make_grouped\", \"doors_grouped\", \"seats_grouped\"]\n",
    "# data_cleaner.convert_columns_to_ordinal(columns_to_ordinal, X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using an ExtraTreesClassifier\n",
    "<u> What is an ExtraTrees Model and How does it differ to a Random Forest? </u>  \n",
    "Extra trees are also know as <a href=\"https://orbi.uliege.be/bitstream/2268/9357/1/geurts-mlj-advance.pdf\"><b>Extremely Random Trees</b></a>\n",
    "\n",
    "- Random forest uses boostrap replicas (subsamples input with replacement)\n",
    "- Extra Trees use whole original sample (bootstrapping is optional arg in scikit)\n",
    "- Random forest chooses the optimum split for each branch\n",
    "- Extra Trees choose these splits randomly\n",
    "- Extra trees are computationally more efficient than other ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"is_private_plate\",\n",
    "\"mileage_deviation_encoded\",\n",
    "\"image_count\",\n",
    "\"advert_sentiment\",\n",
    "\"advert_title_sentiment\",\n",
    "\"make_grouped\",\n",
    "\"fuel_type_grouped\",\n",
    "\"doors_grouped\",\n",
    "\"seats_grouped\",\n",
    "\"owners_grouped\",\n",
    "\"engine_size_grouped\",\n",
    "\"co2_grouped\"]\n",
    "\n",
    "X_train = np.array(X_train[columns_to_keep])\n",
    "X_test = np.array(X_test[columns_to_keep])\n",
    "y_train = np.reshape(np.array(y_train), (-1, ))\n",
    "y_test = np.reshape(np.array(y_test), (-1, ))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1337, test_size=0.1)\n",
    "# extra_tree_clf = ExtraTreesClassifier(n_estimators=20, max_depth=16, min_samples_split=4, random_state=1337, bootstrap=True)\n",
    "# extra_tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_dict = dict(zip(X_train.columns, extra_tree_clf.feature_importances_))\n",
    "# importance_dict = dict(sorted(importance_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "# for k,v in importance_dict.items():\n",
    "#     print(f\"{k} : {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance_dict\n",
    "# print(f\"Old shape: {X_train.shape}\")\n",
    "# model = SelectFromModel(extra_tree_clf, prefit=True)\n",
    "# X_new = model.transform(X_train)\n",
    "# features_out = model.get_feature_names_out(input_features=X_train.columns)\n",
    "# print(f\"New shape: {X_new.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for f in features_out:\n",
    "#     print(f\"{f} : {importance_dict[f]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Choice\n",
    "1. MAE\n",
    " - Easy to interpret and gives less weight to outliers\n",
    "2. MSE\n",
    "- Will  be sensitive to hypercar outliers and needs reformatting for interpretation\n",
    "3. RMSE\n",
    "- Also sensitive to hypercar outliers but already rooted so easier to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_new\n",
    "# X_test = model.transform(X_test)\n",
    "def output_score(scores):\n",
    "    print(f\"Mean: {abs(scores.mean()):.3f} (std: {scores.std():.3f})\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=32, random_state=1337)\n",
    "basic_dt_scores = cross_val_score(dt, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, max_depth=16, random_state=1337)\n",
    "basic_rf_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=100, max_depth=16, random_state=1337, learning_rate=0.3)\n",
    "basic_gb_scores = cross_val_score(gb, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT\n",
      "Mean: 7094.560 (std: 97.362)\n",
      "\n",
      "\n",
      "RF\n",
      "Mean: 5914.527 (std: 58.325)\n",
      "\n",
      "\n",
      "GB\n",
      "Mean: 6591.903 (std: 64.129)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DT\")\n",
    "output_score(basic_dt_scores)\n",
    "print(\"RF\")\n",
    "output_score(basic_rf_scores)\n",
    "print(\"GB\")\n",
    "output_score(basic_gb_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Performing 'Default' Model: Random Forest\n",
    "#### Random Forest Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_rf = RandomForestRegressor(random_state=1337)\n",
    "# param_grid = {'n_estimators':[120], 'max_depth':[16], 'min_samples_split': [16]}\n",
    "# grid_cv_clf = GridSearchCV(cv_rf, param_grid)\n",
    "# grid_cv_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RandomForestRegressor(max_depth=16, min_samples_split=16, n_estimators=120,\n",
    "                      random_state=1337)\n",
    "\"\"\"\n",
    "best_rf = RandomForestRegressor(max_depth=16, min_samples_split=16, n_estimators=120,\n",
    "                      random_state=1337)\n",
    "                      \n",
    "tuned_rf_scores = cross_val_score(best_rf, X_train, y_train, cv=5, scoring='neg_mean_absolute_error')                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic RF\n",
      "Mean: 5914.527 (std: 58.325)\n",
      "\n",
      "\n",
      "Tuned RF\n",
      "Mean: 5879.341 (std: 57.489)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Basic RF\")\n",
    "output_score(basic_rf_scores)\n",
    "print(\"Tuned RF\")\n",
    "output_score(tuned_rf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I accidentally chose some good starting params for my base model as my Grid search returned very similar values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "I am going to use their Scikit API wrapper to keep the implementation similar to previous models\n",
    "\n",
    "TODO: Fill in what XGBoost is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:26372.56836\tvalidation_0-mae:13414.70606\n",
      "[1]\tvalidation_0-rmse:22661.56055\tvalidation_0-mae:10188.07129\n",
      "[2]\tvalidation_0-rmse:20781.36719\tvalidation_0-mae:8238.74609\n",
      "[3]\tvalidation_0-rmse:19783.68555\tvalidation_0-mae:7076.14502\n",
      "[4]\tvalidation_0-rmse:19489.26758\tvalidation_0-mae:6418.01562\n",
      "[5]\tvalidation_0-rmse:19178.58203\tvalidation_0-mae:6038.39941\n",
      "[6]\tvalidation_0-rmse:19196.21289\tvalidation_0-mae:5848.92432\n",
      "[7]\tvalidation_0-rmse:19297.47266\tvalidation_0-mae:5752.18799\n",
      "[8]\tvalidation_0-rmse:19372.88672\tvalidation_0-mae:5704.11084\n",
      "[9]\tvalidation_0-rmse:19353.30469\tvalidation_0-mae:5671.17676\n",
      "[10]\tvalidation_0-rmse:19500.33984\tvalidation_0-mae:5666.64697\n",
      "[11]\tvalidation_0-rmse:19652.96289\tvalidation_0-mae:5667.53906\n",
      "[12]\tvalidation_0-rmse:19766.30859\tvalidation_0-mae:5677.73340\n",
      "[13]\tvalidation_0-rmse:19896.79297\tvalidation_0-mae:5692.77197\n",
      "[14]\tvalidation_0-rmse:20008.83203\tvalidation_0-mae:5706.61084\n",
      "[15]\tvalidation_0-rmse:20088.37305\tvalidation_0-mae:5717.26514\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "             eval_metric=['rmse', 'mae'], gamma=0, gpu_id=-1,\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.3, max_delta_step=0, max_depth=16,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=200, n_jobs=12, num_parallel_tree=1,\n",
       "             predictor='cpu_predictor', random_state=1337, reg_alpha=0,\n",
       "             reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method='exact',\n",
       "             validate_parameters=1, verbosity=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a validation set to enable the use of early stopping\n",
    "# final split: 60 train : 10 val : 30 test\n",
    "# will move this up so other base models are trained on same amount of data\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1337, test_size=0.1)\n",
    "\n",
    "\n",
    "reg = xgb.XGBRegressor(\n",
    "    # Number of boosting rounds\n",
    "    n_estimators=200, \n",
    "    max_depth=16,\n",
    "    learning_rate=0.3,\n",
    "    verbosity=1,\n",
    "    booster='gbtree',\n",
    "    random_state=1337,\n",
    "    predictor='cpu_predictor',   # [cpu_predictor, gpu_predictor]\n",
    "    eval_metric=['rmse', 'mae'] # last eval metric will be evaluated on for early stopping\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "reg.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the base model is able to attain a reasonable validation MAE of approx. 5.7k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Hyperopt for Tuning XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "\n",
    "space={'max_depth': hp.quniform(\"max_depth\", 2, 18, 2),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 180,\n",
    "        'seed': 1337\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "def objective(space):\n",
    "    clf = xgb.XGBRegressor(\n",
    "                    n_estimators = space['n_estimators'], \n",
    "                    max_depth = int(space['max_depth']), \n",
    "                    gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),\n",
    "                    min_child_weight = int(space['min_child_weight']),\n",
    "                    colsample_bytree = int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), (X_val, y_val)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"mae\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    y_pred = clf.predict(X_val)\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    print (\"MAE:\", mae)\n",
    "    return {'loss': -mae, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:                                                   \n",
      "9437.862823619736                                      \n",
      "MAE:                                                                             \n",
      "9440.020801302508                                                                \n",
      "MAE:                                                                             \n",
      "9465.854586766083                                                                \n",
      "MAE:                                                                             \n",
      "9465.854584958308                                                                \n",
      "MAE:                                                                             \n",
      "9437.712209012263                                                                \n",
      "MAE:                                                                             \n",
      "9437.50248353033                                                                 \n",
      "MAE:                                                                             \n",
      "9437.862583270608                                                                \n",
      "MAE:                                                                             \n",
      "9440.020755085314                                                                \n",
      "MAE:                                                                             \n",
      "9465.85442285591                                                                 \n",
      "MAE:                                                                             \n",
      "9437.890874631623                                                                \n",
      "MAE:                                                                              \n",
      "9437.84664059507                                                                  \n",
      "MAE:                                                                              \n",
      "9437.84704790536                                                                  \n",
      "MAE:                                                                              \n",
      "9437.862812858153                                                                 \n",
      "MAE:                                                                              \n",
      "9437.84704790536                                                                  \n",
      "MAE:                                                                              \n",
      "9439.084149338905                                                                 \n",
      "MAE:                                                                              \n",
      "9439.083889376858                                                                 \n",
      "MAE:                                                                              \n",
      "9440.01997663959                                                                  \n",
      "MAE:                                                                              \n",
      "9437.502905252557                                                                 \n",
      "MAE:                                                                              \n",
      "9437.862636821377                                                                 \n",
      "MAE:                                                                              \n",
      "9437.84708880943                                                                  \n",
      "MAE:                                                                              \n",
      "9424.991636196008                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991665480044                                                                 \n",
      "MAE:                                                                              \n",
      "9465.85448308095                                                                  \n",
      "MAE:                                                                              \n",
      "9465.854534191705                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854597430995                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991390752237                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084329928955                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020682727874                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991517246282                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084331145095                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854589090091                                                                 \n",
      "MAE:                                                                              \n",
      "9437.891309754594                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854606705756                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020830327463                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020725375918                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854465045726                                                                 \n",
      "MAE:                                                                              \n",
      "9424.99177163806                                                                  \n",
      "MAE:                                                                              \n",
      "9439.08428027602                                                                  \n",
      "MAE:                                                                              \n",
      "9440.020603885641                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854612616313                                                                 \n",
      "MAE:                                                                              \n",
      "9437.891000661642                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991787774636                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854226572044                                                                 \n",
      "MAE:                                                                              \n",
      "9437.712190934504                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084232326455                                                                 \n",
      "MAE:                                                                              \n",
      "9437.86318008415                                                                  \n",
      "MAE:                                                                              \n",
      "9440.020422450672                                                                 \n",
      "MAE:                                                                              \n",
      "9437.50303799938                                                                  \n",
      "MAE:                                                                              \n",
      "9465.854534073766                                                                 \n",
      "MAE:                                                                              \n",
      "9424.99100928251                                                                  \n",
      "MAE:                                                                              \n",
      "9437.86325396515                                                                  \n",
      "MAE:                                                                              \n",
      "9437.891213341165                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020236533968                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084055539503                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991427828078                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854614795311                                                                 \n",
      "MAE:                                                                              \n",
      "9437.503122879778                                                                 \n",
      "MAE:                                                                              \n",
      "9440.02077064959                                                                  \n",
      "MAE:                                                                              \n",
      "9439.084182451174                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991634254822                                                                 \n",
      "MAE:                                                                              \n",
      "9437.863160658777                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854576089572                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020779481589                                                                 \n",
      "MAE:                                                                              \n",
      "9437.890850339754                                                                 \n",
      "MAE:                                                                              \n",
      "9437.71254220567                                                                  \n",
      "MAE:                                                                              \n",
      "9465.85460826605                                                                  \n",
      "MAE:                                                                              \n",
      "9424.991739233436                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854502637798                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020745967164                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854592183612                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991693897895                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854589090091                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854529354214                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991735865366                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084232326455                                                                 \n",
      "MAE:                                                                              \n",
      "9440.02073567734                                                                  \n",
      "MAE:                                                                              \n",
      "9439.08434599786                                                                  \n",
      "MAE:                                                                              \n",
      "9465.854454781038                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020773337084                                                                 \n",
      "MAE:                                                                              \n",
      "9424.990954736013                                                                 \n",
      "MAE:                                                                              \n",
      "9424.991533982227                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854526691852                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084499606612                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020742498553                                                                 \n",
      "MAE:                                                                              \n",
      "9465.85446557549                                                                  \n",
      "MAE:                                                                              \n",
      "9424.991603110808                                                                 \n",
      "MAE:                                                                              \n",
      "9437.863160658777                                                                 \n",
      "MAE:                                                                              \n",
      "9437.846293850109                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084413471406                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020422450672                                                                 \n",
      "MAE:                                                                              \n",
      "9465.85458825484                                                                  \n",
      "MAE:                                                                              \n",
      "9440.020801302508                                                                 \n",
      "MAE:                                                                              \n",
      "9424.9915191952                                                                   \n",
      "MAE:                                                                              \n",
      "9465.854410963257                                                                 \n",
      "MAE:                                                                              \n",
      "9437.891258158541                                                                 \n",
      "MAE:                                                                              \n",
      "9424.99156178911                                                                  \n",
      "MAE:                                                                              \n",
      "9437.862889592925                                                                 \n",
      "MAE:                                                                              \n",
      "9439.084331978413                                                                 \n",
      "MAE:                                                                              \n",
      "9465.854578804136                                                                 \n",
      "MAE:                                                                              \n",
      "9440.020841212787                                                                 \n",
      "100%|██████████| 100/100 [00:31<00:00,  3.14trial/s, best loss: -9465.854614795311]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Different XGB Implementation with Cross-Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1337, test_size=0.1)\n",
    "xgb_dtrain = xgb.DMatrix(X_train, y_train)\n",
    "# xgb_dval = xgb.DMatrix(X_val, y_val)\n",
    "xgb_dtest = xgb.DMatrix(X_test, y_test)\n",
    "param = {\n",
    "    'max_depth': 16, \n",
    "    'eta': 0.1, \n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae'\n",
    "    }\n",
    "evallist = [(xgb_dtrain, 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 1000\n",
    "bst = xgb.cv(param, xgb_dtrain, num_round, metrics='mae', early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-mae-mean</th>\n",
       "      <th>train-mae-std</th>\n",
       "      <th>test-mae-mean</th>\n",
       "      <th>test-mae-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16925.475912</td>\n",
       "      <td>63.494392</td>\n",
       "      <td>16937.354818</td>\n",
       "      <td>143.993683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15323.347005</td>\n",
       "      <td>59.199637</td>\n",
       "      <td>15371.183268</td>\n",
       "      <td>144.886182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13912.184570</td>\n",
       "      <td>56.058313</td>\n",
       "      <td>14018.279622</td>\n",
       "      <td>144.999213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12671.313477</td>\n",
       "      <td>52.929467</td>\n",
       "      <td>12844.576823</td>\n",
       "      <td>144.611386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11574.495443</td>\n",
       "      <td>47.230916</td>\n",
       "      <td>11823.134115</td>\n",
       "      <td>147.078306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10608.156576</td>\n",
       "      <td>44.584086</td>\n",
       "      <td>10936.218424</td>\n",
       "      <td>145.644828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9755.651693</td>\n",
       "      <td>39.352714</td>\n",
       "      <td>10173.391602</td>\n",
       "      <td>143.546164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9005.082031</td>\n",
       "      <td>36.323444</td>\n",
       "      <td>9518.486979</td>\n",
       "      <td>144.321584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8343.281901</td>\n",
       "      <td>32.993114</td>\n",
       "      <td>8952.847331</td>\n",
       "      <td>141.189245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7757.857910</td>\n",
       "      <td>30.422887</td>\n",
       "      <td>8467.227214</td>\n",
       "      <td>137.015820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7241.935547</td>\n",
       "      <td>27.206582</td>\n",
       "      <td>8052.604492</td>\n",
       "      <td>132.942202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6787.351237</td>\n",
       "      <td>23.294079</td>\n",
       "      <td>7696.643066</td>\n",
       "      <td>130.514922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6385.609863</td>\n",
       "      <td>22.813068</td>\n",
       "      <td>7395.033691</td>\n",
       "      <td>125.224406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6029.868001</td>\n",
       "      <td>22.724928</td>\n",
       "      <td>7136.558105</td>\n",
       "      <td>120.719408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5715.843750</td>\n",
       "      <td>22.176347</td>\n",
       "      <td>6917.667480</td>\n",
       "      <td>116.984096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5438.301432</td>\n",
       "      <td>21.379858</td>\n",
       "      <td>6732.508138</td>\n",
       "      <td>111.962300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5190.867838</td>\n",
       "      <td>24.064514</td>\n",
       "      <td>6577.392415</td>\n",
       "      <td>104.200816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4972.071940</td>\n",
       "      <td>23.914580</td>\n",
       "      <td>6449.649251</td>\n",
       "      <td>99.106515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4779.970215</td>\n",
       "      <td>24.599424</td>\n",
       "      <td>6343.207194</td>\n",
       "      <td>97.266542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4607.988118</td>\n",
       "      <td>24.739067</td>\n",
       "      <td>6254.499837</td>\n",
       "      <td>95.056471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4453.913248</td>\n",
       "      <td>25.014780</td>\n",
       "      <td>6180.829427</td>\n",
       "      <td>94.686392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4314.965006</td>\n",
       "      <td>20.852586</td>\n",
       "      <td>6121.194824</td>\n",
       "      <td>95.556050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4189.025879</td>\n",
       "      <td>19.649759</td>\n",
       "      <td>6069.670247</td>\n",
       "      <td>93.547805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4077.737142</td>\n",
       "      <td>17.780592</td>\n",
       "      <td>6028.526855</td>\n",
       "      <td>92.855676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3974.916097</td>\n",
       "      <td>19.310210</td>\n",
       "      <td>5992.516764</td>\n",
       "      <td>89.490316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>3884.040446</td>\n",
       "      <td>21.423277</td>\n",
       "      <td>5964.524089</td>\n",
       "      <td>86.389913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3800.151204</td>\n",
       "      <td>19.670994</td>\n",
       "      <td>5942.479492</td>\n",
       "      <td>84.612336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3724.574626</td>\n",
       "      <td>18.524778</td>\n",
       "      <td>5926.399414</td>\n",
       "      <td>80.737283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3655.868164</td>\n",
       "      <td>17.414757</td>\n",
       "      <td>5915.053223</td>\n",
       "      <td>76.202239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3588.933187</td>\n",
       "      <td>16.635151</td>\n",
       "      <td>5906.452962</td>\n",
       "      <td>73.186205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3527.733887</td>\n",
       "      <td>14.977942</td>\n",
       "      <td>5900.689616</td>\n",
       "      <td>69.985118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3472.890381</td>\n",
       "      <td>14.907797</td>\n",
       "      <td>5897.728353</td>\n",
       "      <td>67.426626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3421.692789</td>\n",
       "      <td>13.262857</td>\n",
       "      <td>5894.336263</td>\n",
       "      <td>65.135768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3373.158447</td>\n",
       "      <td>12.724367</td>\n",
       "      <td>5894.483398</td>\n",
       "      <td>62.708225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3326.825846</td>\n",
       "      <td>15.139081</td>\n",
       "      <td>5893.579101</td>\n",
       "      <td>61.385706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-mae-mean  train-mae-std  test-mae-mean  test-mae-std\n",
       "0     16925.475912      63.494392   16937.354818    143.993683\n",
       "1     15323.347005      59.199637   15371.183268    144.886182\n",
       "2     13912.184570      56.058313   14018.279622    144.999213\n",
       "3     12671.313477      52.929467   12844.576823    144.611386\n",
       "4     11574.495443      47.230916   11823.134115    147.078306\n",
       "5     10608.156576      44.584086   10936.218424    145.644828\n",
       "6      9755.651693      39.352714   10173.391602    143.546164\n",
       "7      9005.082031      36.323444    9518.486979    144.321584\n",
       "8      8343.281901      32.993114    8952.847331    141.189245\n",
       "9      7757.857910      30.422887    8467.227214    137.015820\n",
       "10     7241.935547      27.206582    8052.604492    132.942202\n",
       "11     6787.351237      23.294079    7696.643066    130.514922\n",
       "12     6385.609863      22.813068    7395.033691    125.224406\n",
       "13     6029.868001      22.724928    7136.558105    120.719408\n",
       "14     5715.843750      22.176347    6917.667480    116.984096\n",
       "15     5438.301432      21.379858    6732.508138    111.962300\n",
       "16     5190.867838      24.064514    6577.392415    104.200816\n",
       "17     4972.071940      23.914580    6449.649251     99.106515\n",
       "18     4779.970215      24.599424    6343.207194     97.266542\n",
       "19     4607.988118      24.739067    6254.499837     95.056471\n",
       "20     4453.913248      25.014780    6180.829427     94.686392\n",
       "21     4314.965006      20.852586    6121.194824     95.556050\n",
       "22     4189.025879      19.649759    6069.670247     93.547805\n",
       "23     4077.737142      17.780592    6028.526855     92.855676\n",
       "24     3974.916097      19.310210    5992.516764     89.490316\n",
       "25     3884.040446      21.423277    5964.524089     86.389913\n",
       "26     3800.151204      19.670994    5942.479492     84.612336\n",
       "27     3724.574626      18.524778    5926.399414     80.737283\n",
       "28     3655.868164      17.414757    5915.053223     76.202239\n",
       "29     3588.933187      16.635151    5906.452962     73.186205\n",
       "30     3527.733887      14.977942    5900.689616     69.985118\n",
       "31     3472.890381      14.907797    5897.728353     67.426626\n",
       "32     3421.692789      13.262857    5894.336263     65.135768\n",
       "33     3373.158447      12.724367    5894.483398     62.708225\n",
       "34     3326.825846      15.139081    5893.579101     61.385706"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b419173de24494810e65c4ea4d4c859b912f4352999b480e23ee82152eb9c1e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pyZak')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
